{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "h-vPu-WIBHgF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader,random_split,Subset\n",
        "from torchvision import datasets,transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constants And Transforms"
      ],
      "metadata": {
        "id": "9olymmvMClYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED=123 #ensure reproducibility by controling randomnes in training\n",
        "BATHC_SIZE=256 # no of images into the model at each training step\n",
        "NUM_EPOCHS=50 # No of complete passes through the training dataset\n",
        "DEVICE=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5L9H3o9CVL2",
        "outputId": "7754a8eb-170d-4a47-bfef-ae020102113f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def set_all_seeds(seed):\n",
        "#     torch.manual_seed(seed)\n",
        "#     torch.cuda.manual_seed(seed)\n",
        "#     torch.cuda.manual_seed_all(seed) # for multi- GPU\n",
        "#     np.RANDOM_SEED(seed)\n",
        "#     RANDOM_SEED(seed)\n",
        "#     # cuDNN! may use non-deterministic algorithms that run faster but may give slightly different results each time you run the code\n",
        "#     torch.backend.cudnn.deterministic=True\n",
        "#     torch.backends.cudnn.benchmark = False #banchmark =want reproducible and stable results, or when your input sizes change frequently.\n",
        "\n"
      ],
      "metadata": {
        "id": "u5eoPa2GDGXO"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def set_all_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # If using multi-GPU\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        " # cuDNN! may use non-deterministic algorithms that run faster but may give slightly different results each time you run the code\n",
        "    torch.backends.cudnn.deterministic = True\n",
        " #banchmark =want reproducible and stable results, or when your input sizes change frequently.\n",
        "    torch.backends.cudnn.benchmark = False\n"
      ],
      "metadata": {
        "id": "vZaLFFRxGYTP"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 123\n",
        "set_all_seeds(RANDOM_SEED)\n"
      ],
      "metadata": {
        "id": "tQ6B7PJIHEr0"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Augmentation & Normalization"
      ],
      "metadata": {
        "id": "QkJRP6ltJxEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms=torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((70,70)),# resize the images 70x70\n",
        "    torchvision.transforms.RandomCrop((64,64)), # randomly crop 64x64 data augmentation\n",
        "    torchvision.transforms.ToTensor(), # converts image to pyTorch tensor[0,1]\n",
        "    torchvision.transforms.Normalize(0.5,0.5,0.5),(0.5,0.5,0.5)]) # shift pixel value from [0,1]to [-1,1] > mean=0.5,std=0.5"
      ],
      "metadata": {
        "id": "deAy4c-wHGQK"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_transforms=torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((70,70)),\n",
        "    torchvision.transforms.RandomCrop((64,64)),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(0.5,0.5,0.5),(0.5,0.5,0.5)])"
      ],
      "metadata": {
        "id": "a53F41GOIuez"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading CIFAR-10 Data"
      ],
      "metadata": {
        "id": "173ethTFKsc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloaders_cifar10(batch_size, validation_fraction, train_transforms, test_transforms, num_workers=2):\n",
        "   # Download CIFAR-10 train and test datasets\n",
        "    train_dataset = datasets.CIFAR10(root='data', train=True, download=True, transform=train_transforms)\n",
        "    test_dataset = datasets.CIFAR10(root='data', train=False, download=True, transform=test_transforms)\n",
        "\n",
        "    # Create a validation split from the training dataset\n",
        "    num_train = len(train_dataset)\n",
        "    indices = list(range(num_train))\n",
        "    split = int(np.floor(validation_fraction * num_train))\n",
        "\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "    train_data = Subset(train_dataset, train_idx)\n",
        "    valid_data = Subset(train_dataset, valid_idx)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "    return train_loader, valid_loader, test_loader"
      ],
      "metadata": {
        "id": "PyUN_cXqLz1d"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, valid_loader, test_loader = get_dataloaders_cifar10(\n",
        "    batch_size=256,\n",
        "    validation_fraction=0.1,\n",
        "    train_transforms=train_transforms,\n",
        "    test_transforms=test_transforms,\n",
        "    num_workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "8bkQ0psMOVX0"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for images, labels in train_loader:\n",
        "#     print('Image batch dimensions:', images.shape)\n",
        "#     print('Image label dimensions:', labels.shape)\n",
        "#     print('Class labels of 10 examples:', labels[:10])\n",
        "#     break\n"
      ],
      "metadata": {
        "id": "RW492mPvO2kl"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "fkAGptW1cQ4K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build Convolutional Blocks(1-5)"
      ],
      "metadata": {
        "id": "icGyCWJyciGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class VGG16(torch.nn.Module):\n",
        "    def __init__(self,num_classes):\n",
        "      super().__init__()\n",
        "\n",
        "\n",
        "      self.block_1=torch.nn.Sequential(\n",
        "    torch.nn.conv2d(3,64,kernel_size=3,padding=1), # input (RGB Image)3x64x64\n",
        "    torch.nn.RELU(),\n",
        "    torch.nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.MaxPool2d(kernel_size=2,stride=2))\n",
        "      # Two conv layers with 64 filters, followed by ReLU, then max pooling.\n",
        "\n",
        "      self.block_2=torch.nn.Sequential(\n",
        "          torch.nn.Conv2d(64,128,kernel_size=3,padding=1),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.Conve2d(128,128,kernel_size=3,padding=1),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.MaxPool2d(kernel_size=2,stride=2))\n",
        "\n",
        "\n",
        "      self.block_3=torch.nn.Sequential(\n",
        "          torch.nn.Conv2d(128,256,kernel_size=3,padding=1),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.Conv2d(256,256,kernel_size=3,padding=1),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.Conv2d(256,256,kernel_size=3,padding=1),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.Maxpool2d(kernel_size=2,stride=2))\n",
        "\n",
        "\n",
        "      self.block_4=torch.nn.Sequential(\n",
        "          torch.nn.Conv2d(256,512,kernel_size=3,padding=1),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.Conv2d(512,512,kernel_size=3,padding=1),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.Conv2d(512,512,kernel_size=3,padding=1),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.Maxpool2d(kernel_size=2,stride=2))\n",
        "\n",
        "\n",
        "      self.block_5=torch.nn.Sequential(\n",
        "          torch.nn.Conv2d(512,512,kernel_size=3,padding=1),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.Conv2d(512,512,kernel_size=3,padding=1),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.Conv2d(512,512,kernel_size=3,padding=1),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.Maxpool2d(kernel_size=2,stride=2))\n",
        "\n",
        "\n",
        "      self.avgpool=torch.nn.AdaptiveAvgpool2d((3,3))\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "Ea94chfQPjlt"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# self.classifier = torch.nn.Sequential(\n",
        "#     torch.nn.Linear(512*3*3, 4096),\n",
        "#     torch.nn.ReLU(True),\n",
        "#     torch.nn.Dropout(p=0.5),\n",
        "#     torch.nn.Linear(4096, 4096),\n",
        "#     torch.nn.ReLU(True),\n",
        "#     torch.nn.Dropout(p=0.5),\n",
        "#     torch.nn.Linear(4096, num_classes),\n",
        "# )"
      ],
      "metadata": {
        "id": "Qu-L_Nm7SCvP"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classifier"
      ],
      "metadata": {
        "id": "E0pBG1igcdMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG16(torch.nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        # ... other blocks ...\n",
        "\n",
        "        self.classifier = torch.nn.Sequential(\n",
        "            torch.nn.Linear(512 * 3 * 3, 4096),\n",
        "            torch.nn.ReLU(True),\n",
        "            torch.nn.Dropout(p=0.5),\n",
        "            torch.nn.Linear(4096, 4096),\n",
        "            torch.nn.ReLU(True),\n",
        "            torch.nn.Dropout(p=0.5),\n",
        "            torch.nn.Linear(4096, num_classes)  # use it directly here\n",
        "        )\n"
      ],
      "metadata": {
        "id": "IgfsliF-Zhn4"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG16(torch.nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        # ... define your blocks and classifier here ...\n",
        "\n",
        "        # Initialize weights for Conv and Linear layers\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
        "                torch.nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    m.bias.detach().zero_()\n"
      ],
      "metadata": {
        "id": "AbbC7n0caQfc"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, x):\n",
        "    x = self.block_1(x)\n",
        "    x = self.block_2(x)\n",
        "    x = self.block_3(x)\n",
        "    x = self.block_4(x)\n",
        "    x = self.block_5(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = x.view(x.size(0), -1) # flatten to (batch_size, 512*3*3)\n",
        "    logits = self.classifier(x)\n",
        "    return logits\n"
      ],
      "metadata": {
        "id": "UNOScFL8acEJ"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG16(num_classes=10)\n",
        "print(sum(p.numel() for p in model.parameters()))  # should print a large number > 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAoBQ8cHbj7T",
        "outputId": "92f596af-12a7-4a48-feba-da6b717d0f7c"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Whr9lckYcHaF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}