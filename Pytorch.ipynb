{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "### Deep Learning\n"
      ],
      "metadata": {
        "id": "dSANVb2ON5Aa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "I7LQ_7d3NbLv",
        "outputId": "5169581e-2654-4f76-adb9-edfb034ed357"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"''\\n1.Data\\n2.Create Model\\n3.Optimize model paramter)(finding the best weights)\\n4.Save the trained model\\n\\nthis 4 steps every importante in every DL concept\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "'''''\n",
        "1.Data\n",
        "2.Create Model\n",
        "3.Optimize model paramter)(finding the best weights)\n",
        "4.Save the trained model\n",
        "\n",
        "this 4 steps every importante in every DL concept\n",
        "\n",
        "'''''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing  The Librabies\n"
      ],
      "metadata": {
        "id": "OkxSQkAaPDEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "0u_kOFG4PAMG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download The Data Set"
      ],
      "metadata": {
        "id": "mv0c56FyPzv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data=datasets.FashionMNIST(root=\"data\",train=True,download=True,transform=ToTensor())"
      ],
      "metadata": {
        "id": "e1OLuZvMPxrN"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data=datasets.FashionMNIST(root=\"data\",train=False,download=True,transform=ToTensor())"
      ],
      "metadata": {
        "id": "BRGlJxPMQO2P"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AdAq8NTRFKV",
        "outputId": "e2a737e0-ef59-4aa5-8e1c-acde14762c73"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vebCZFmHRnUA",
        "outputId": "92c2cbad-e051-4c0f-a5e4-faa984743b42"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Batch Size"
      ],
      "metadata": {
        "id": "Bvvsvcu1STFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### we create batching size of this dataset\n",
        "batch_size=64\n",
        "tarin_dataloader=DataLoader(training_data,batch_size=batch_size)\n",
        "test_dataloader=DataLoader(test_data,batch_size=batch_size)"
      ],
      "metadata": {
        "id": "4NWARRu6Rztn"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in test_dataloader:\n",
        "  print(x.shape)\n",
        "  print(y.shape) #y is only 64 batch_size\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYYmR4FRS59l",
        "outputId": "5ac9bb6c-4c10-4666-c667-b8be5edd5aa1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create The Model"
      ],
      "metadata": {
        "id": "hEXhAFPCUWut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select the device\n",
        "device=\"cuda\" if torch.cuda.is_available() else\"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CphPPrS4TGfc",
        "outputId": "dcec6764-a272-460d-83fa-b45ca3b5e2dc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module): ## like to \"Inheritance child class is nn.model ,parant class (def in the pytorchlibrary) \"\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "\n",
        "    self.flatten=nn.Flatten() # flatten is convert \"multi-dimensional input\"\n",
        "    self.linear1=nn.liner(28*28,512) ## numbers are \"Hidden layers\"\n",
        "    self.linear2=nn.linear(512,512)\n",
        "    self.linear3=nn.linear(512,10)\n",
        "    self.relu=nn.Relu() ## acrtivation function\n"
      ],
      "metadata": {
        "id": "zbgbMfCjU1uN"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forword(self,x):# is always use to pass input to \"neural network\"\n",
        "   x=self.flatten(x)\n",
        "   x=self.linear1(x)\n",
        "   x=self.relu(x)\n",
        "   x+self.linear2(x)\n",
        "   x=self.relu(x)\n",
        "   x=self.linear3(x)\n",
        "   return x"
      ],
      "metadata": {
        "id": "JPFS1o49XaB4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)# copies your entire architecture to the \"GPU\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POTjnkNHYDvl",
        "outputId": "ee7c0275-e6e7-44a2-da2f-9116dde213ab"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear1): Linear(in_features=784, out_features=512, bias=True)\n",
            "  (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (linear3): Linear(in_features=512, out_features=10, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimization-Gradient Descent+Backpropogation"
      ],
      "metadata": {
        "id": "5MyNUXD0a-jb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Use LossFunction\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=1e-3) ##SGD means \"stochastuc Gradient descent\""
      ],
      "metadata": {
        "id": "w2wXiBXhah2u"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Descent Step"
      ],
      "metadata": {
        "id": "GpyPiz-cbulT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "> Batch of the input\n",
        "> Pass it to the Model\n",
        "> Compute loss function\n",
        "> Update the weights\n"
      ],
      "metadata": {
        "id": "ZM-s7jq_bfvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Corrected train function with proper indentation\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    model.train()  # Set model to training mode\n",
        "    for batch, (X, Y) in enumerate(dataloader):\n",
        "  ##>> enumerate>> adds an index (counter) to an iterable, such as a list or a loop.\n",
        "        X = X.to(device)  # Move input data to GPU/CPU\n",
        "        Y = Y.to(device) # Move labels to GPU/CPU\n",
        "\n",
        "        # Forward pass\n",
        "        #Prediction\n",
        "        pred = model(X)\n",
        "        #loss function\n",
        "        loss = loss_fn(pred, Y)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()  # Clear previous gradients\n",
        "        loss.backward()  # Compute gradients\n",
        "        optimizer.step()  # Update model parameters"
      ],
      "metadata": {
        "id": "AqBsFQXYeoGc"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if batch_size %100==0:\n",
        "  print(f'loss of the model{loss.item()}')"
      ],
      "metadata": {
        "id": "p5hhGwRmflyA"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def test(dataloader,model,loss_fn):\n",
        "#   model.eval() # evaluation\n",
        "#   num_batched=len(dataloader)\n",
        "#   tess_loss,correct=0\n",
        "#   with torch.no_grad():\n",
        "#     for X,Y in dataloader:\n",
        "#       A=X.to(device)\n",
        "#       B=Y.to(device)\n",
        "#       pred=model(A)\n",
        "#       #compute prediction\n",
        "#       pred=model(A)\n",
        "#       # Compute loss funtion\n",
        "#       test_loss+=loss_fn(pred,B).item()\n",
        "\n",
        "#       # #we find how many correct prediction\n",
        "#       correct+=(pred.argmax(1)==B).type(torch.float).sum().item()\n",
        "#   # test_loss/=num_batched\n",
        "#   # correct/=num_batched\n",
        "#   test_loss=test_loss/num_batched\n",
        "#   correct=correct/len(dataloader.dataset)"
      ],
      "metadata": {
        "id": "A2SgRIKTgisZ"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f'Test Accuracy{100* correct},avg_loss,{test-loss}')"
      ],
      "metadata": {
        "id": "QLrJtN09h_TU"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    test_loss = 0  # Correct variable name\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # No gradients needed for testing\n",
        "        for X, Y in dataloader:\n",
        "            X, Y = X.to(device), Y.to(device)\n",
        "            outputs = model(X)\n",
        "            test_loss += loss_fn(outputs, Y).item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == Y).sum().item()\n",
        "            total += Y.size(0)\n",
        "\n",
        "    avg_loss = test_loss / len(dataloader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Test Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "rN9dEBWQjMoL"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Training Phase\n",
        "\n",
        "epochs=5\n",
        "for t in range(epochs):\n",
        "  print(f'Epochs{t+1}')\n",
        "  train(tarin_dataloader,model,loss_fn,optimizer)\n",
        "  test(test_dataloader,model,loss_fn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXHT7ivClluA",
        "outputId": "60e17fb0-3dd4-47c8-82de-b5863da9d0b4"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs1\n",
            "Test Loss: 0.8123, Accuracy: 69.99%\n",
            "Epochs2\n",
            "Test Loss: 0.7814, Accuracy: 71.46%\n",
            "Epochs3\n",
            "Test Loss: 0.7557, Accuracy: 72.58%\n",
            "Epochs4\n",
            "Test Loss: 0.7335, Accuracy: 73.75%\n",
            "Epochs5\n",
            "Test Loss: 0.7139, Accuracy: 74.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save The Model"
      ],
      "metadata": {
        "id": "JBoFOXGalxN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "save_path = \"/content/FashMNIST\"\n",
        "os.makedirs(save_path, exist_ok=True) #Create folder if needed\n",
        "# Save model\n",
        "torch.save(model.state_dict(), os.path.join(save_path, \"FashMNIST.pth\"))\n",
        "print(\"Model saved successfully!\")\n",
        "\n",
        "# Load model\n",
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load(os.path.join(save_path, \"FashMNIST.pth\")))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nP2oKY3Gmdzd",
        "outputId": "7b2305c3-4450-44df-b3db-23921e95d8f0"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully!\n",
            "Model loaded successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-97-b48529eb3b65>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(os.path.join(save_path, \"FashMNIST.pth\")))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## PREDICTION\n",
        "\n",
        "# Define class labels correctly\n",
        "classes = [\"T-shirt/top\", \"Trousers\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "           \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"]\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Select a test sample\n",
        "x, y = test_data[0]  # Get the first image and label\n",
        "x = x.unsqueeze(0)  # Add batch dimension (1, 1, 28, 28)\n",
        "\n",
        "with torch.no_grad():  # Disable gradient computation for inference\n",
        "    x = x.to(device)  # Move input to GPU if available\n",
        "    pred = model(x)  # Forward pass\n",
        "    predicted_label = classes[pred.argmax(1).item()]  # Get class name\n",
        "    actual_label = classes[y]  # Get actual class name\n",
        "\n",
        "# Print the results\n",
        "print(f'Predicted: {predicted_label}')\n",
        "print(f'Actual: {actual_label}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afs67dTTo_n8",
        "outputId": "999f8b7e-f3ec-4738-b7ce-54a574bf945a"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: Ankle Boot\n",
            "Actual: Ankle Boot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bt5chfi8p2wf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}